{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed walk through for PtyRAD\n",
    "\n",
    "- Created with PtyRAD 0.1.0b8\n",
    "- Requires PtyRAD >= 0.1.0b8\n",
    "- Latest demo params files / scripts: https://github.com/chiahao3/ptyrad/tree/main/demo\n",
    "- Documentation: https://ptyrad.readthedocs.io/en/latest/\n",
    "\n",
    "**Before running this notebook, you must first follow the instruction in `README.md` to:**\n",
    "1. Create the Python environment with all dependant Python packages like PyTorch\n",
    "2. Activate that python environment\n",
    "3. Install `ptyrad` package into your activated Python environement (only need to install once)\n",
    "4. Download the demo data into `demo/data/` from the `demo/data/data_url.txt`\n",
    "\n",
    "> Note: This notebook is designed for showcasing only the \"reconstruction\" mode, most of the wrapper class / functions are exposed so that you can see how different components work together.\n",
    "\n",
    "Author: Chia-Hao Lee, cl2696@cornell.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Change this to the ABSOLUTE PATH to the demo/ folder so you can correctly access data/ and params/\n",
    "work_dir = \"../\" # Leave this as-is if you're running the notebook from the `ptyrad/demo/scripts/` folder, this will change it back to demo/\n",
    "\n",
    "os.chdir(work_dir)\n",
    "print(\"Current working dir: \", os.getcwd())\n",
    "# The printed working dir should be \".../ptyrad/demo\" to locate the demo params files easily\n",
    "# Note that the output/ directory will be automatically generated under your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptyrad.load import load_params\n",
    "from ptyrad.initialization import Initializer\n",
    "from ptyrad.models import PtychoAD\n",
    "from ptyrad.losses import CombinedLoss\n",
    "from ptyrad.constraints import CombinedConstraint\n",
    "from ptyrad.reconstruction import recon_step, create_optimizer, make_batches, select_scan_indices\n",
    "from ptyrad.save import save_results, copy_params_to_dir, make_output_folder\n",
    "from ptyrad.utils import (\n",
    "    CustomLogger,\n",
    "    get_blob_size,\n",
    "    parse_sec_to_time_str,\n",
    "    print_system_info,\n",
    "    set_gpu_device,\n",
    "    time_sync,\n",
    "    vprint,\n",
    ")\n",
    "from ptyrad.visualization import (\n",
    "    plot_forward_pass,\n",
    "    plot_pos_grouping,\n",
    "    plot_scan_positions,\n",
    "    plot_summary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CustomLogger(log_file='ptyrad_log.txt', log_dir='auto', prefix_time='datetime', show_timestamp=True)\n",
    "\n",
    "print_system_info()\n",
    "device = set_gpu_device(gpuid=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Initialize optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = \"params/tBL_WSe2_reconstruct.yml\"\n",
    "\n",
    "# We enable validation to auto-fill defaults and check parameter consistency since PtyRAD 0.1.0b8\n",
    "# If you run into issues with validation (e.g., false positives or unexpected errors),\n",
    "# you can temporarily disable it by setting `validate=False` and prepare a fully complete params file yourself.\n",
    "# If this happens, please report the bug so we can improve the validation logic.\n",
    "params              = load_params(params_path, validate=True)\n",
    "init_params         = params.get('init_params')\n",
    "hypertune_params    = params.get('hypertune_params') # It's parsed but not needed in this demo notebook\n",
    "model_params        = params.get('model_params')\n",
    "loss_params         = params.get('loss_params')\n",
    "constraint_params   = params.get('constraint_params')\n",
    "recon_params        = params.get('recon_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = Initializer(init_params).init_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = init.init_variables[\"crop_pos\"] + init.init_variables[\"probe_pos_shifts\"]\n",
    "plot_scan_positions(pos, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PtychoAD(init.init_variables, model_params, device=device)\n",
    "optimizer = create_optimizer(model.optimizer_params, model.optimizable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, init.init_variables[\"N_scans\"], 2)\n",
    "dp_power = 0.5\n",
    "plot_forward_pass(model, indices, dp_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the loss and constraint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CombinedLoss(loss_params, device=device)\n",
    "\n",
    "constraint_fn = CombinedConstraint(constraint_params, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Main optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NITER             = recon_params.get('NITER')\n",
    "INDICES_MODE      = recon_params.get('INDICES_MODE')\n",
    "batch_config      = recon_params.get('BATCH_SIZE', {})\n",
    "grad_accumulation = batch_config.get(\"grad_accumulation\", 1)\n",
    "batch_size        = batch_config.get('size') * grad_accumulation\n",
    "GROUP_MODE        = recon_params.get('GROUP_MODE')\n",
    "SAVE_ITERS        = recon_params.get('SAVE_ITERS')\n",
    "output_dir        = recon_params.get('output_dir')\n",
    "recon_dir_affixes = recon_params.get('recon_dir_affixes')\n",
    "selected_figs     = recon_params.get('selected_figs')\n",
    "copy_params       = recon_params.get('copy_params')\n",
    "\n",
    "pos = (model.crop_pos + model.opt_probe_pos_shifts).detach().cpu().numpy() # The .to(torch.float32) upcast is a preventive solution because .numpy() doesn't support bf16\n",
    "probe_int = model.get_complex_probe_view().abs().pow(2).sum(0).detach().cpu().numpy()\n",
    "dx = init.init_variables[\"dx\"]\n",
    "d_out = get_blob_size(dx, probe_int, output=\"d90\")  # d_out unit is in Ang\n",
    "\n",
    "indices = select_scan_indices(\n",
    "    init.init_variables['N_scan_slow'],\n",
    "    init.init_variables['N_scan_fast'],\n",
    "    subscan_slow=INDICES_MODE.get('subscan_slow'),\n",
    "    subscan_fast=INDICES_MODE.get('subscan_fast'),\n",
    "    mode=INDICES_MODE.get('mode', 'random'),\n",
    ")\n",
    "\n",
    "batches = make_batches(indices, pos, batch_size, mode=GROUP_MODE)\n",
    "vprint(f\"The effective batch size (i.e., how many probe positions are simultaneously used for 1 update of ptychographic parameters) is batch_size * grad_accumulation = {batch_size} * {grad_accumulation} = {batch_size*grad_accumulation}\")\n",
    "\n",
    "fig_grouping = plot_pos_grouping(\n",
    "    pos,\n",
    "    batches,\n",
    "    circle_diameter=d_out / dx,\n",
    "    diameter_type=\"90%\",\n",
    "    dot_scale=1,\n",
    "    show_fig=True,\n",
    "    pass_fig=True,\n",
    ")\n",
    "\n",
    "if SAVE_ITERS is not None:\n",
    "    output_path = make_output_folder(\n",
    "        output_dir,\n",
    "        indices,\n",
    "        init_params,\n",
    "        recon_params,\n",
    "        model,\n",
    "        constraint_params,\n",
    "        loss_params,\n",
    "        recon_dir_affixes\n",
    "    )\n",
    "    \n",
    "    fig_grouping.savefig(output_path + \"/summary_pos_grouping.png\")\n",
    "\n",
    "    if copy_params:\n",
    "        copy_params_to_dir(params_path, output_path, params)\n",
    "\n",
    "# Flush to file after the output_path is created\n",
    "if logger is not None and logger.flush_file:\n",
    "    logger.flush_to_file(log_dir = output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time_sync()\n",
    "vprint(\"### Starting the PtyRADSolver in reconstruction mode ###\")\n",
    "vprint(\" \")\n",
    "\n",
    "for niter in range(1, NITER + 1):\n",
    "\n",
    "    shuffle(batches)\n",
    "    batch_losses = recon_step(\n",
    "        batches, grad_accumulation, model, optimizer, loss_fn, constraint_fn, niter\n",
    "    )\n",
    "\n",
    "    ## Saving intermediate results\n",
    "    if SAVE_ITERS is not None and niter % SAVE_ITERS == 0:\n",
    "        with torch.no_grad():\n",
    "        # Note that `params` stores the original params from the configuration file, \n",
    "        # while `model` contains the actual params that could be updated by meas_crop, meas_pad, or meas_resample\n",
    "            save_results(\n",
    "                output_path,\n",
    "                model,\n",
    "                params,\n",
    "                optimizer,\n",
    "                niter,\n",
    "                indices,\n",
    "                batch_losses,\n",
    "            )\n",
    "\n",
    "            ## Saving summary\n",
    "            plot_summary(\n",
    "                output_path,\n",
    "                model,\n",
    "                niter,\n",
    "                indices,\n",
    "                init.init_variables,\n",
    "                selected_figs=selected_figs,\n",
    "                show_fig=False,\n",
    "                save_fig=True,\n",
    "            )\n",
    "vprint(f\"### Finish {NITER} iterations, averaged iter_t = {np.mean(model.iter_times):.5g} sec ###\")\n",
    "vprint(\" \")\n",
    "end_t = time_sync()\n",
    "solver_t = end_t - start_t\n",
    "time_str = f\", or {parse_sec_to_time_str(solver_t)}\" if solver_t > 60 else \"\"\n",
    "vprint(f\"### The PtyRADSolver is finished in {solver_t:.3f} sec {time_str} ###\")\n",
    "\n",
    "if logger is not None and logger.flush_file:\n",
    "    logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptyrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
