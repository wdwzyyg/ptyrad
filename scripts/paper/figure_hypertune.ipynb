{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure - BO showcase\n",
    "\n",
    "Note that you'll need `plotly` for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "work_dir = \"H:\\workspace\\ptyrad\"\n",
    "os.chdir(work_dir)\n",
    "print(\"Current working dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_from_str(string):\n",
    "    import re\n",
    "    # Regular expression to find the number after \"_error_\"\n",
    "    match = re.search(r'_error_([\\d.eE+-]+)', string)\n",
    "\n",
    "    if match:\n",
    "        return f\"{float(match.group(1)):.5f}\"  # Ensures 5 decimal places\n",
    "    else:\n",
    "        print(\"No match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def get_error_vs_time_from_studies(study, elasped_time=14400, timepoints=200):\n",
    "    \"\"\" Calculate optimization history of a study / studies \"\"\"\n",
    "    from optuna.study import Study\n",
    "    \n",
    "    if isinstance(study, Study):\n",
    "        studies = [study]\n",
    "    else:\n",
    "        studies = list(study)\n",
    "    \n",
    "    optimization_histories = []\n",
    "    for study in studies:\n",
    "    \n",
    "        trials = study.get_trials()\n",
    "            \n",
    "        # 1. Get the start and end time of the study (convert to seconds)\n",
    "        first_start_time = trials[0].datetime_start.timestamp()\n",
    "\n",
    "        # 2. Filter only completed trials\n",
    "        completed_trials = [t for t in trials if t.state == 1] # 1 is complete, 2 is pruned\n",
    "\n",
    "        # 3. Collect start times and errors for completed trials\n",
    "        start_times = np.array([t.datetime_start.timestamp() - first_start_time for t in completed_trials])\n",
    "        errors = np.array([t.values for t in completed_trials])\n",
    "\n",
    "        # 4. Compute best-so-far (cumulative minimum)\n",
    "        best_so_far = np.minimum.accumulate(errors).squeeze()\n",
    "\n",
    "        # 5. Create a common time grid from 0 to last_end_time - first_start_time\n",
    "        common_time_grid = np.linspace(0, elasped_time, timepoints)\n",
    "\n",
    "        # 6. Interpolate\n",
    "        interp_func = interp1d(start_times, best_so_far, kind='previous', fill_value=\"extrapolate\")\n",
    "        interpolated_errors = interp_func(common_time_grid)\n",
    "        optimization_histories.append(interpolated_errors)\n",
    "    return np.array(optimization_histories), common_time_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler + Pruner panel (Average after interpolate in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_random       = \"sqlite:///hypertune_optuna_ZSM5_random_contrast_seed.sqlite3\"\n",
    "path_random_prune = \"sqlite:///hypertune_optuna_ZSM5_random_prune_contrast_seed.sqlite3\"\n",
    "path_TPE          = \"sqlite:///hypertune_optuna_ZSM5_TPE_contrast_seed.sqlite3\"\n",
    "path_TPE_prune    = \"sqlite:///hypertune_optuna_ZSM5_TPE_prune_contrast_seed.sqlite3\"\n",
    "\n",
    "labels = ['Random',\n",
    "          'Random + Pruner',\n",
    "          'TPE', \n",
    "          'TPE + Pruner']\n",
    "\n",
    "paths = [path_random, \n",
    "         path_random_prune,\n",
    "         path_TPE, \n",
    "         path_TPE_prune]\n",
    "\n",
    "round_idx = 20\n",
    "studies_all = []\n",
    "histories_all = []\n",
    "figs = []\n",
    "arrs = []\n",
    "for i, path in enumerate(paths):\n",
    "    studies = [optuna.load_study(study_name=f'study_{str(idx).zfill(2)}', storage=path) for idx in range(round_idx)]\n",
    "    print(f\"\\nFound {len(studies)} studies in database: {path}\")\n",
    "    print(f\"Each study contains in average {np.mean([len(study.get_trials()) for study in studies]):.2f} trials\")\n",
    "    \n",
    "    num_completed = 0\n",
    "    num_pruned = 0\n",
    "    for study in studies:\n",
    "        for trial in study.get_trials():\n",
    "            if trial.state == 1:\n",
    "                num_completed += 1\n",
    "            elif trial.state == 2:\n",
    "                num_pruned += 1\n",
    "    print(f\"Each study contains in average {num_completed/len(studies):.2f} completed and {num_pruned/len(studies):.2f} pruned trials\")\n",
    "    \n",
    "    histories, time_grid = get_error_vs_time_from_studies(studies, elasped_time=14400, timepoints=200)\n",
    "    studies_all.append(studies)\n",
    "    histories_all.append(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# https://optuna.readthedocs.io/en/stable/reference/generated/optuna.importance.PedAnovaImportanceEvaluator.html\n",
    "# The importance can be interpreted as how important each hyperparameter is to get the performance better than baseline.\n",
    "# If evaluate on local, the importances imply how importance each parameter is during optimization. Meanwhile, evaluate_on_local=False gives the importances in the specified search_space.\n",
    "\n",
    "# path_importance   = \"sqlite:///hypertune/hypertune.sqlite3\"\n",
    "path_importance   = \"sqlite:///hypertune_importance_ZSM5.sqlite3\"\n",
    "study_names = optuna.study.get_all_study_names(storage=path_importance)\n",
    "# study_name = 'optimization_tBL_WSe2_random'\n",
    "study_name = 'contrast'\n",
    "study = optuna.load_study(study_name=study_name, storage=path_importance)\n",
    "evaluator = optuna.importance.PedAnovaImportanceEvaluator(baseline_quantile=0.10, evaluate_on_local=True)\n",
    "plotly_fig = plot_param_importances(study, evaluator=evaluator)\n",
    "\n",
    "# Extract data from the Plotly figure\n",
    "data = plotly_fig.data[0]  # Assuming only one trace\n",
    "hyperparameters = data.y   # Hyperparameter names\n",
    "importances = data.x       # Importance values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "from tifffile import imread\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "\n",
    "mpl.rc('xtick', direction='in')\n",
    "mpl.rc('xtick.major', width=1, size=3.5)\n",
    "mpl.rc('xtick.minor', width=1, size=2)\n",
    "mpl.rc('ytick', direction='in')\n",
    "mpl.rc('ytick.major', width=1, size=3.5)\n",
    "mpl.rc('ytick.minor', width=1, size=2)\n",
    "\n",
    "# Global font/line control\n",
    "linewidth = 1.2\n",
    "markersize = 4\n",
    "fontsize_title = 11\n",
    "fontsize_subtitle = 7\n",
    "fontsize_label = 9\n",
    "fontsize_legend = 7\n",
    "\n",
    "# Scale bar settings\n",
    "scale_bar_length = 20/0.3591  # Length of the scale bar in pixels (1 px = 0.3591 Ang)\n",
    "scale_bar_label = \"2 nm\"  # Label for the scale bar\n",
    "scale_bar_color = \"white\"\n",
    "fontprops = fm.FontProperties(size=10)\n",
    "\n",
    "shadow_offset = [-0.01, -0.01]\n",
    "text_offset = [0.5,0.92]\n",
    "\n",
    "# Create figure with constrained layout\n",
    "fig = plt.figure(figsize=(7, 4), dpi=300, constrained_layout=False)\n",
    "gs0 = fig.add_gridspec(2, 1, height_ratios=[1, 0.67], hspace=0.35)  # Two main rows\n",
    "\n",
    "gs00 = gs0[0].subgridspec(1, 2, width_ratios=[1, 1], wspace=0.20)  # Top row with 2 subplots\n",
    "gs01 = gs0[1].subgridspec(1, 5, wspace=0)  # Bottom row with 5 image panels\n",
    "\n",
    "# Panel a: Optimization History\n",
    "linestyles = [':', '-.', '--', '-']  # Define different linestyles\n",
    "ax1 = fig.add_subplot(gs00[0])\n",
    "for i, label in enumerate(labels):\n",
    "    line = histories_all[i].mean(0)\n",
    "    ax1.plot(time_grid/60, line, label=label, linewidth=linewidth, linestyle=linestyles[i])\n",
    "ax1.set_title('Optimization History', fontsize=fontsize_title)\n",
    "ax1.set_xlabel('Elapsed Time (min)', fontsize=fontsize_label)\n",
    "ax1.set_ylabel('Image Contrast', fontsize=fontsize_label)\n",
    "ax1.set_xticks([0, 60, 120, 180, 240])\n",
    "ax1.text(-0.1, 1.08, 'a', transform=ax1.transAxes, fontsize=16, fontweight='bold')\n",
    "ax1.legend(fontsize=fontsize_legend)\n",
    "\n",
    "# Panel b: Hyperparameter Importances\n",
    "hyperparameters = ['lr\\nobj. ph.', 'optimizer', 'lr\\nprobe', 'batch size']\n",
    "ax2 = fig.add_subplot(gs00[1])\n",
    "ax2.set_title('Hyperparameter Importances', fontsize=fontsize_title)\n",
    "ax2.bar(hyperparameters, importances, color='C0')\n",
    "ax2.set_ylabel('Importance', fontsize=fontsize_label)\n",
    "ax2.text(-0.1, 1.08, 'c', transform=ax2.transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "# Bottom row: Image panels (5 individual subplots)\n",
    "output_dir = 'H:\\workspace\\ptyrad\\output\\paper\\ZSM5/20250205_ptyrad_ZSM5_optuna_seed/hypertune_TPESampler_contrast_03'\n",
    "\n",
    "# Get files from folder\n",
    "all_files = os.listdir(output_dir)\n",
    "file_names = []\n",
    "for file in all_files:\n",
    "    if file.startswith('objp_zsum_crop_08bit_error_'):\n",
    "        file_names.append(file)\n",
    "file_names.sort()\n",
    "# Get images and errors\n",
    "errors = []\n",
    "imgs = []\n",
    "for file_name in file_names:\n",
    "    imgs.append(imread(os.path.join(output_dir, file_name)))\n",
    "    errors.append(get_error_from_str(file_name))\n",
    "# Sort images with error ()\n",
    "idx_sort = np.argsort(errors)\n",
    "imgs_sort = np.array(imgs)[idx_sort]\n",
    "selected_indices = np.linspace(0, len(imgs_sort)-1, gs01.ncols, endpoint=True, dtype=int)\n",
    "error_values = np.array(errors)[idx_sort][selected_indices]\n",
    "\n",
    "for i in range(gs01.ncols):\n",
    "    ax = fig.add_subplot(gs01[i])\n",
    "    if i ==0:\n",
    "        ax.text(-0.20, 1.08, 'b', transform=ax.transAxes, fontsize=16, fontweight='bold')\n",
    "    ax.imshow(imgs_sort[selected_indices[i]], cmap=\"gray\")  # Replace with actual images\n",
    "    ax.axis(\"off\")  # Hide axes\n",
    "    \n",
    "    # Add scale bar\n",
    "    if i == 0:\n",
    "        scalebar = AnchoredSizeBar(ax.transData, scale_bar_length, scale_bar_label,\n",
    "                                loc='lower right', pad=0.5, color=scale_bar_color, frameon=False, size_vertical=3, label_top=True,\n",
    "                                fontproperties=fontprops)\n",
    "    else:\n",
    "        scalebar = AnchoredSizeBar(ax.transData, scale_bar_length, '',\n",
    "                                loc='lower right', pad=0.5, color=scale_bar_color, frameon=False, size_vertical=3, label_top=True,\n",
    "                                fontproperties=fontprops)\n",
    "    ax.add_artist(scalebar)\n",
    "    \n",
    "    # Add label with text shadow\n",
    "    error = f\"{np.float32(error_values[i]):.3f}\"\n",
    "    ax.text(\n",
    "        text_offset[0] + shadow_offset[0], text_offset[1] + shadow_offset[1], error,\n",
    "        color='black', fontsize=12, fontweight='bold', transform=ax.transAxes,\n",
    "        va='top', ha='center', alpha=0.6\n",
    "    )\n",
    "    ax.text(\n",
    "        text_offset[0], text_offset[1], error, color='white', fontsize=12, fontweight='bold',\n",
    "        va='top', ha='center', transform=ax.transAxes,\n",
    "    )\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
