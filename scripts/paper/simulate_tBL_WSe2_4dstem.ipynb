{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate tBL-WSe2 4D-STEM data\n",
    "\n",
    "Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2025.02.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Because the supercell is relatively small, Numba will keep complaining NumbaPerformanceWarning due to under utilization\n",
    "\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ase\n",
    "import abtem\n",
    "import dask\n",
    "import cupy as cp\n",
    "from cupyx.scipy import ndimage\n",
    "\n",
    "abtem.config.set({\"local_diagnostics.progress_bar\": True})\n",
    "abtem.config.set({\"device\": \"gpu\"})\n",
    "abtem.config.set({\"dask.chunk-size-gpu\" : \"2048 MB\"})\n",
    "dask.config.set({\"num_workers\": 1});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_to_phase(projected_atomic_potential, acceleration_voltage):\n",
    "    \n",
    "    # proj_potential: V-Ang\n",
    "    # acceleration_voltage: kV\n",
    "    \n",
    "    # Physical Constants\n",
    "    PLANCKS = 6.62607015E-34 # m^2*kg / s\n",
    "    REST_MASS_E = 9.1093837015E-31 # kg\n",
    "    CHARGE_E = 1.602176634E-19 # coulomb \n",
    "    SPEED_OF_LIGHT = 299792458 # m/s\n",
    "    \n",
    "    # Useful constants in EM unit \n",
    "    hc = PLANCKS * SPEED_OF_LIGHT / CHARGE_E*1E-3*1E10 # 12.398 keV-Ang, h*c\n",
    "    REST_ENERGY_E = REST_MASS_E*SPEED_OF_LIGHT**2/CHARGE_E*1E-3 # 511 keV, m0c^2\n",
    "    \n",
    "    # Derived values\n",
    "    gamma = 1 + acceleration_voltage / REST_ENERGY_E # m/m0 = 1 + e*V/m0c^2, dimensionless, Lorentz factor\n",
    "    wavelength = hc/np.sqrt((2*REST_ENERGY_E + acceleration_voltage)*acceleration_voltage) # Angstrom, lambda = hc/sqrt((2*m0c^2 + e*V)*e*V))\n",
    "    sigma = 2*np.pi*gamma*REST_MASS_E*CHARGE_E*wavelength/PLANCKS**2 * 1E-20 * 1E3 # interaction parameter, 2 pi*gamma*m0*e*lambda/h^2, 1/kV-Ang\n",
    "    phase_shift = np.angle(np.exp(1j*sigma * projected_atomic_potential/1E3)) # radian in strong phase approximation\n",
    "    \n",
    "    return gamma, wavelength, sigma, phase_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "work_dir = \"H:\\workspace\\ptyrad\"\n",
    "os.chdir(work_dir)\n",
    "print(\"Current working dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptyrad.utils import compose_affine_matrix\n",
    "from ptyrad.visualization import plot_affine_transformation, plot_scan_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup abTEM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up random seed\n",
    "random_seed = 42\n",
    "\n",
    "# Atomic model\n",
    "mx2_formula = 'WSe2'\n",
    "mx2_phase = '2H'\n",
    "lattice_constant = 3.297\n",
    "uc_thickness = 3.376\n",
    "vacuum_layers = 2\n",
    "supercell_reps = (26,15,1) #(26,15,1)#(38, 22, 1) # ~ 120 Ang extent with orthogonalized cell\n",
    "\n",
    "# Phonon\n",
    "use_frozen_phonon = True\n",
    "num_phonon_configs = 25\n",
    "phonon_sigma = 0.1 # Ang\n",
    "\n",
    "# Potential Sampling\n",
    "lateral_sampling = 0.1494/1.5 # unit: Ang, note that kmax_antialias = 1/(3*dx), so if we want to simulate up to kmax = 4.1 1/Ang, we need 1/4.1/3 Ang sampling or slightly finer ~ 0.08 Ang \n",
    "vertical_sampling = 1 # Ang, multislice thickness\n",
    "\n",
    "# Random defects\n",
    "vac_density = 0.02\n",
    "\n",
    "# Probe parameters\n",
    "energy = 80e3 # unit: eV\n",
    "wavelength = 0.041757 # unit: Ang, this value is only used for display useful information\n",
    "convergence_angles = 24.9 #\n",
    "df = 0 # df, unit: Ang, note the df = -C1,0, so positive defocus is underfocuse just like Kirkland and fold_slice.\n",
    "C30_list = 500 * 1e-9 * 1e10 # unit: Ang, note that we convert to m and then Ang. C30 = Cs.\n",
    "aberrations = {\"C30\": C30_list}\n",
    "\n",
    "# Temporal partial coherence\n",
    "use_partial_temporal_probe = True\n",
    "chromatic_aberration = 1 * 1e-3 * 1e10 # unit: Ang, note that we convert to m and then Ang\n",
    "energy_spread = 0.35 # unit: eV, this is the std so expected FWHM of ZLP would be 2.355*0.35 ~ 0.82 eV\n",
    "num_df_configs = 5\n",
    "\n",
    "# Scan configurations\n",
    "N_scan_fast, N_scan_slow = 128,128\n",
    "scan_step_size = 0.429 # Unit: Ang.\n",
    "# (scale, asymmetry, rotation, shear) = (1.005, 0.03, 1.5, 1.2)\n",
    "scan_rand_std = 0.05 # Unit: Ang\n",
    "\n",
    "# Spatial partial coherence\n",
    "use_partial_spatial_source = True\n",
    "source_size = 0.34 # Unit: Ang. 2.355*std = FWHM. Note that this mixes the DP along scan directions\n",
    "\n",
    "# Final CBED\n",
    "target_Npix = 128\n",
    "material = 'simu_tBL_WSe2'\n",
    "output_dir = f'data/paper/{material}'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f'output_dir = {output_dir} is created!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make moire supercell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the \"top\" is in real specimen space, in abTEM the \"top layer\" is put at 0 and is visualized as the lower layer\n",
    "\n",
    "atoms_top = ase.build.mx2(formula=mx2_formula, kind=mx2_phase, a=lattice_constant, thickness=uc_thickness, vacuum=vacuum_layers) # a: lattice constant, thickness: chalcogen intralayer distance, vacuum = vacuum layer thickness. All unit in Ang.\n",
    "atoms_top.cell[-1,-1] *= 2\n",
    "\n",
    "atoms_bottom = ase.build.mx2(formula=mx2_formula, kind=mx2_phase, a=lattice_constant, thickness=uc_thickness, vacuum=vacuum_layers) # a: lattice constant, thickness: chalcogen intralayer distance, vacuum = vacuum layer thickness. All unit in Ang.\n",
    "atoms_bottom.cell[-1,-1] *= 2\n",
    "atoms_bottom.positions[:, 2] += 6.491 # shift WSe2 layer in the z-direction, note that +z is actually illuminated later, so abTEM is having beam propagating from 0 to +z\n",
    "\n",
    "atoms_top_sc = abtem.orthogonalize_cell(atoms_top) * supercell_reps # lx:ly = 1:sqrt(3)\n",
    "atoms_bottom_sc = abtem.orthogonalize_cell(atoms_bottom) * supercell_reps # lx:ly = 1:sqrt(3)\n",
    "\n",
    "rotation_offset = 8 # deg\n",
    "inter_twist = 183 # deg\n",
    "\n",
    "atoms_top_sc.rotate(rotation_offset + inter_twist, \"z\", rotate_cell=False)\n",
    "atoms_bottom_sc.rotate(rotation_offset, \"z\", rotate_cell=False)\n",
    "\n",
    "atoms_top_sc.positions[:, :2] += (np.diag(atoms_top_sc.cell/2)[:2] - atoms_top_sc.positions.mean(0)[:2])\n",
    "atoms_bottom_sc.positions[:, :2] += (np.diag(atoms_bottom_sc.cell/2)[:2] - atoms_bottom_sc.positions.mean(0)[:2])\n",
    "\n",
    "tBL_sc = atoms_top_sc + atoms_bottom_sc\n",
    "\n",
    "print(f'tBL_sc.cell = {tBL_sc.cell} Ang') # Unit: Ang\n",
    "print(f'Supercell tBL_sc contains {len(np.where(tBL_sc.get_atomic_numbers() == 34)[0])} Se atoms and {len(np.where(tBL_sc.get_atomic_numbers() == 74)[0])} W atoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce vacancies into the chalcogen sites in the supercell\n",
    "num_atoms = tBL_sc.get_global_number_of_atoms()\n",
    "Se_indices = np.where(tBL_sc.get_atomic_numbers() == 34)[0]\n",
    "num_Se_atoms = len(Se_indices)\n",
    "\n",
    "np.random.seed(seed=random_seed)\n",
    "vac_idx = np.random.choice(Se_indices, size = int(vac_density * num_Se_atoms), replace=False)\n",
    "print(f\"Introducing {len(vac_idx)} Se vacancies\")\n",
    "print(f\"First 5 vac_idx = {vac_idx[:5]}\")\n",
    "if vac_density > 0:\n",
    "    del tBL_sc[vac_idx]\n",
    "print(f'Supercell tBL_sc contains {len(np.where(tBL_sc.get_atomic_numbers() == 34)[0])} Se atoms and {len(np.where(tBL_sc.get_atomic_numbers() == 74)[0])} W atoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "abtem.show_atoms(tBL_sc, ax=ax1, scale=0.05, title=\"tBL-WSe2 beam view\")\n",
    "abtem.show_atoms(tBL_sc, ax=ax2, plane=\"xz\", scale=0.5, title=\"tBL-WSe2 side view\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make object potential w/o phonon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the potential with or without phonon\n",
    "if use_frozen_phonon:\n",
    "    print(f\"Using FrozenPhonons potential with {num_phonon_configs} configs\")\n",
    "    np.random.seed(random_seed)\n",
    "    phonon_seed = np.random.randint(0,1000, num_phonon_configs)\n",
    "    print(f'phonon_seed = {phonon_seed}')\n",
    "    atoms = abtem.FrozenPhonons(tBL_sc, num_configs=num_phonon_configs, sigmas=phonon_sigma, seed=phonon_seed)\n",
    "    potential = abtem.Potential(atoms=atoms, sampling=lateral_sampling, parametrization=\"lobato\",\n",
    "        slice_thickness=vertical_sampling, projection=\"finite\")\n",
    "    potential_arr = cp.mean(potential.build().compute(progress_bar=False).array, axis=0).transpose(0,2,1)\n",
    "else:\n",
    "    print(\"Using Static potential\")\n",
    "    atoms = tBL_sc\n",
    "    potential = abtem.Potential(atoms=atoms, sampling=lateral_sampling, parametrization=\"lobato\",\n",
    "        slice_thickness=vertical_sampling, projection=\"finite\")\n",
    "    potential_arr = potential.build().compute(progress_bar=False).array.transpose(0,2,1)\n",
    "print(f\"potential.shape = {potential.shape}, potential_arr.shape = {potential_arr.shape}.\")\n",
    "print(\"Note that the last 2 axes are transposed because abTEM go with (z,x,y) but we want (z,y,x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make probe w/o temporal partial coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probe\n",
    "kmax_antialias = 1/lateral_sampling/3 # 1/Ang #The kmax_antialiasing = 2.675 Ang-1 \n",
    "alpha_max_antialias = wavelength * kmax_antialias # rad\n",
    "\n",
    "print(f\"Energy = {energy/1e3} kV, rel. wavelength = {wavelength} Ang\")\n",
    "print(f\"CBED collection kmax = {kmax_antialias:.4f} 1/Ang, collection alpha_max = {alpha_max_antialias*1000:.4f} mrad\")\n",
    "\n",
    "if use_partial_temporal_probe:\n",
    "    focal_spread = chromatic_aberration * energy_spread / energy\n",
    "    defocus_distribution = abtem.distributions.gaussian(\n",
    "    center = df,\n",
    "    standard_deviation=focal_spread,\n",
    "    num_samples=num_df_configs,\n",
    "    sampling_limit=2,\n",
    "    ensemble_mean=True)\n",
    "    print(f\"Using partial temporal coherent probe with {len(np.array(defocus_distribution))} defoci\")\n",
    "    print(f\"Focal spread = {focal_spread:.4f} Ã…\")\n",
    "    print(f\"defocus distribution = {np.array(defocus_distribution).round(3)}\")\n",
    "    probe = abtem.Probe(energy=energy, semiangle_cutoff=convergence_angles, defocus=defocus_distribution, **aberrations)\n",
    "else:\n",
    "    print(\"Using coherent probe\")\n",
    "    probe = abtem.Probe(energy=energy, semiangle_cutoff=convergence_angles, defocus=df,                   **aberrations)\n",
    "probe.grid.match(potential)\n",
    "print(f\"probe.shape = {probe.shape}\")\n",
    "print(probe.axes_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scan pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scan positions, unit in Ang\n",
    "pos = scan_step_size * np.array([(y, x) for y in range(N_scan_slow) for x in range(N_scan_fast)]) # (N,2), each row is (y,x)\n",
    "# pos = pos - (pos.max(0) - pos.min(0))/2 + pos.min(0) # Center scan around origin\n",
    "\n",
    "# # Apply affine transformation\n",
    "# plot_affine_transformation(scale, asymmetry, rotation, shear)\n",
    "\n",
    "# Apply random jitter\n",
    "np.random.seed(random_seed)\n",
    "# pos_real = pos @ compose_affine_matrix(scale, asymmetry, rotation, shear) + scan_rand_std * np.random.randn(*pos.shape)\n",
    "pos_real = pos + scan_rand_std * np.random.randn(*pos.shape)\n",
    "\n",
    "\n",
    "# Apply offset to move the scan pattern inside the supercell\n",
    "offset = pos_real.min(0) - 15\n",
    "pos_real -= offset\n",
    "pos -= offset\n",
    "\n",
    "# Change dx due to the antialias kMax\n",
    "recon_dx = lateral_sampling * 1.5  \n",
    "\n",
    "# Parse the position into the hdf5 for reconstuction, and the abTEM scan position\n",
    "pos_ang_yx = pos_real\n",
    "pos_ang_xy = np.flip(pos_real,1)\n",
    "\n",
    "# Preprocess the position so that it's compatible with follow up reconstruction packages\n",
    "pos_px_yx = pos_ang_yx / recon_dx\n",
    "obj_shape = 1.2 * np.ceil(pos_px_yx.max(0) - pos_px_yx.min(0) + np.array([target_Npix, target_Npix])) # Estimate the obj_shape in px\n",
    "pos_px_yx = pos_px_yx + np.ceil((np.array(obj_shape)/2) - (np.array([target_Npix, target_Npix])/2)) # Shift back to obj coordinate\n",
    "\n",
    "# Visualize it in conventional orientation, although abTEM would put origin at the bottom left\n",
    "plot_scan_positions(pos_real, init_pos=pos, dot_scale=0.1, show_arrow=False)\n",
    "print(f\"First 5 positions of pos_ang_xy (Ang) = {pos_ang_xy[:5]}, this is for abTEM\\n\")\n",
    "print(f\"First 5 positions of pos_px_yx (px) = {pos_px_yx[:5]}, this is for reconstruction packages\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbeds = probe.multislice(scan = pos_ang_xy[0], potential = potential).diffraction_patterns().reduce_ensemble().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cbeds all in one, might run into memory issue for 128x128 scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create custom scan pattern\n",
    "# custom_scan = abtem.CustomScan(pos_ang_xy)\n",
    "\n",
    "# # Calculate cbeds\n",
    "# cbeds = probe.multislice(scan = custom_scan, potential = potential).diffraction_patterns().reduce_ensemble().compute()\n",
    "# print(f\"cbeds.shape = {cbeds.shape}\")\n",
    "# print(f\"cbeds.axes_metadata = {cbeds.axes_metadata}\")\n",
    "\n",
    "# print(f\"Selected cbeds.shape = {cbeds.shape}\")\n",
    "# cbeds = cbeds.array\n",
    "\n",
    "# # Apply the partial spatial coherence\n",
    "# if use_partial_spatial_source:\n",
    "#     source_size_std_ang = source_size\n",
    "#     source_size_std_px = source_size_std_ang / scan_step_size\n",
    "#     cbeds = cbeds.reshape(N_scan_slow, N_scan_fast, *cbeds.shape[-2:])\n",
    "#     cbeds = ndimage.gaussian_filter(cbeds, sigma=source_size_std_px)\n",
    "#     print(f\"\\nAdding source size (partial spatial coherence) of Gaussian blur std = {source_size_std_px:.4f} scan_step sizes or {source_size_std_ang:.4f} Ang to measurements along the scan directions\")\n",
    "#     cbeds = cbeds.reshape(-1,*cbeds.shape[-2:])\n",
    "    \n",
    "# # Resample cbeds\n",
    "# cbeds_shape = np.array(cbeds.shape[-2:])\n",
    "# zoom_factors = np.concatenate([[1], target_Npix / cbeds_shape])\n",
    "# cbeds_resample = ndimage.zoom(cbeds, zoom=zoom_factors, order=1) # Use bilinear to prevent value overshoot\n",
    "# print(f\"cbeds_resample.shape = {cbeds_resample.shape}\")\n",
    "\n",
    "# # Cast cupy back to numpy\n",
    "# cbeds_resample = cbeds_resample.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample potential and then crop it to the scan region\n",
    "potential_resample = ndimage.zoom(potential_arr, zoom=(1, 2/3, 2/3), order=1).get() # Don't do any value scaling when we resample laterally because we need to keep the max value\n",
    "print(f\"potential_resample.shape = {potential_resample.shape}\")\n",
    "\n",
    "# Crop the potential based on scan position converted to reconstruction px size\n",
    "pos_recon_px_yx = pos_ang_yx / recon_dx\n",
    "y_min, y_max = np.floor(pos_recon_px_yx[:,0].min()).astype(int), np.ceil(pos_recon_px_yx[:,0].max()).astype(int)\n",
    "x_min, x_max = np.floor(pos_recon_px_yx[:,1].min()).astype(int), np.ceil(pos_recon_px_yx[:,1].max()).astype(int)\n",
    "\n",
    "potential_crop = potential_resample[:,y_min-1:y_max,x_min-1:x_max]\n",
    "print(f\"potential_crop.shape = {potential_crop.shape}\")\n",
    "\n",
    "# Convert potential to phase shifts\n",
    "*_, gt_phase = potential_to_phase(potential_crop, energy/1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the abtem_params as metadata\n",
    "abtem_params = {'material':'tBL-WSe2',\n",
    "                'lateral_sampling':lateral_sampling,\n",
    "                'vertical_sampling':vertical_sampling,\n",
    "                'random_seed':random_seed,\n",
    "                'use_frozen_phonon':use_frozen_phonon,\n",
    "                'num_phonon_configs':num_phonon_configs,\n",
    "                'phonon_sigma':phonon_sigma,\n",
    "                'vac_density':vac_density,\n",
    "                'energy':energy,\n",
    "                'wavelength':wavelength,\n",
    "                'convergence_angles':convergence_angles,\n",
    "                'df':df,\n",
    "                'C30_list':C30_list,\n",
    "                'use_partial_temporal_probe':use_partial_temporal_probe,\n",
    "                'use_partial_spatial_source':use_partial_spatial_source,\n",
    "                'chromatic_aberration':chromatic_aberration,\n",
    "                'energy_spread':energy_spread,\n",
    "                'num_df_configs':num_df_configs,\n",
    "                'N_scan_fast':N_scan_fast,\n",
    "                'N_scan_slow':N_scan_slow,\n",
    "                'scan_step_size':scan_step_size,\n",
    "                'sc_reps':'sc_reps',\n",
    "                'vac_idx':vac_idx,\n",
    "                'num_atoms':num_atoms,\n",
    "                'kmax_antialias':kmax_antialias,\n",
    "                'alpha_max_antialias':alpha_max_antialias,\n",
    "                'target_Npix':target_Npix\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the hdf5 file\n",
    "\n",
    "potential_str = 'phonon' if use_frozen_phonon else 'static'\n",
    "\n",
    "coherent_str = ''\n",
    "if not use_partial_spatial_source and not use_partial_temporal_probe:\n",
    "    coherent_str = '_coherent'\n",
    "if use_partial_temporal_probe:\n",
    "    coherent_str += '_temporal'\n",
    "if use_partial_spatial_source:\n",
    "    coherent_str += '_spatial'\n",
    "\n",
    "mode_str = potential_str + coherent_str\n",
    "filename = mode_str + f'_N{N_scan_slow*N_scan_fast}_dp{target_Npix}.hdf5'\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Check if the file exists and delete it\n",
    "if os.path.exists(output_path):\n",
    "    os.remove(output_path)  # Delete the existing file so we can overwrite\n",
    "\n",
    "with h5py.File(output_path, 'a') as hf:\n",
    "    hf.create_dataset('/full_volume',   data = potential_resample)\n",
    "    hf.create_dataset('/volume',        data = potential_crop)\n",
    "    hf.create_dataset('/gt_phase',      data = gt_phase)\n",
    "    # hf.create_dataset('/dp',            data = cbeds_resample)\n",
    "    param_group = hf.create_group('abtem_params')\n",
    "    for key,value in abtem_params.items():\n",
    "        param_group.create_dataset(key, data=value)\n",
    "print(f\"Saved hdf5 as {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
