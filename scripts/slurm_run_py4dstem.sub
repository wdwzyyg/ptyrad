#!/bin/bash
#SBATCH --job-name=py4dstem
#SBATCH --mail-user=cl2696@cornell.edu       # Where to send mail
#SBATCH --nodes=1                            # number of nodes requested
#SBATCH --ntasks=1                           # number of tasks to run in parallel
#SBATCH --cpus-per-task=4                    # number of CPUs required for each task. 4 for 10GB, 8 for 20GB, 32 for 80GB of A100.
#SBATCH --gres=gpu:a100:1                # request a GPU #gpu:2g.20gb:1
#SBATCH --time=144:00:00                      # Time limit hrs:min:sec
#SBATCH --output=logs/log_job_%j_py4dstem_convergence_tBL_WSe2_batch16_p12_6slice.txt  # Standard output and error log to /logs, you need to create this folder first!

pwd; hostname; date

module load cuda/11.8

source activate py4dstem

## Set the params_path variable
PARAMS_PATH="params/paper/py4dstem_convergence_tBL_WSe2_batch16_p12_6slice.yml"
echo params_path = ${PARAMS_PATH}

python -u ./scripts/run_py4dstem.py --params_path "${PARAMS_PATH}" 2>&1

date